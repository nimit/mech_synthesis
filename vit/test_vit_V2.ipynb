{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746bb70-eb1f-473e-bc2b-97abcf5067f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from vit_model import SingleImageTransformerCLIP\n",
    "from dataset import BarLinkageDataset \n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "from dataset_generation.curve_plot import get_pca_inclination, rotate_curve\n",
    "import scipy.spatial.distance as sciDist\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354fc90-9448-4531-ad0b-f95058e8fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headless simulator version\n",
    "index = 0 # local server index \n",
    "API_ENDPOINT = f\"http://localhost:4000/simulation\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "speedscale = 1\n",
    "steps = 360\n",
    "minsteps = int(steps*20/360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8ae72c-963c-458f-a536-c6737e88084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./weights/transformer_weights_VIT_V2/d2048_h32_n6_bs512_lr0.0001_imgpatch8_best_v2_A100.pth\"\n",
    "data_dir = \"/home/anurizada/Documents/processed_dataset_17\"\n",
    "batch_size = 1\n",
    "\n",
    "dataset = BarLinkageDataset(data_dir=data_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4913484-58cd-4236-bc77-e3cf855f884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model_config = checkpoint['model_config']\n",
    "\n",
    "# Initialize model\n",
    "model = SingleImageTransformerCLIP(\n",
    "    tgt_seq_len=model_config['tgt_seq_len'],\n",
    "    d_model=model_config['d_model'],\n",
    "    h=model_config['h'],\n",
    "    N=model_config['N'],\n",
    "    num_labels=model_config['num_labels'],\n",
    "    vocab_size=model_config['vocab_size'],\n",
    "    img_patch=model_config['img_patch']).to(device)\n",
    "\n",
    "# Load weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ad52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "MAX_SAMPLES = 100  # max number of samples to process\n",
    "SOS_TOKEN, EOS_TOKEN, PAD_TOKEN = 0, 1, 2\n",
    "NUM_SPECIAL_TOKENS = 3\n",
    "NUM_MECH_TYPES = 17\n",
    "BIN_OFFSET = NUM_SPECIAL_TOKENS  # since mech tokens are not in the discrete seq\n",
    "\n",
    "# Define externally:\n",
    "# API_ENDPOINT, HEADERS, speedscale, steps, minsteps, dataloader, model, etc.\n",
    "\n",
    "label_mapping_path = \"/home/anurizada/Documents/processed_dataset_17/label_mapping.json\"\n",
    "coupler_mapping_path = \"/home/anurizada/Documents/transformer/BSIdict.json\"\n",
    "\n",
    "with open(label_mapping_path, \"r\") as f:\n",
    "    label_mapping = json.load(f)\n",
    "index_to_label = label_mapping[\"index_to_label\"]\n",
    "\n",
    "with open(coupler_mapping_path, \"r\") as f:\n",
    "    coupler_mapping = json.load(f)\n",
    "\n",
    "\n",
    "def coupler_index_for(mech_type: str) -> int:\n",
    "    \"\"\"Return coupler curve index from BSIdict.json.\"\"\"\n",
    "    if mech_type in coupler_mapping and \"c\" in coupler_mapping[mech_type]:\n",
    "        cvec = coupler_mapping[mech_type][\"c\"]\n",
    "        if isinstance(cvec, list) and 1 in cvec:\n",
    "            return cvec.index(1)\n",
    "    return -1\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# BINNER\n",
    "# ===============================\n",
    "class CoordinateBinner:\n",
    "    def __init__(self, kappa=1.0, num_bins=200):\n",
    "        self.kappa = kappa\n",
    "        self.num_bins = num_bins\n",
    "        self.bin_edges = np.linspace(-kappa, kappa, num_bins + 1)\n",
    "        self.bin_centers = (self.bin_edges[:-1] + self.bin_edges[1:]) / 2\n",
    "\n",
    "    def bin_to_value_torch(self, bin_index_tensor):\n",
    "        bin_index_tensor = torch.clamp(bin_index_tensor, 0, self.num_bins - 1)\n",
    "        device = bin_index_tensor.device\n",
    "        bin_centers_tensor = torch.tensor(self.bin_centers, device=device, dtype=torch.float32)\n",
    "        return bin_centers_tensor[bin_index_tensor]\n",
    "\n",
    "\n",
    "binner = CoordinateBinner(kappa=1.0, num_bins=201)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# AUTOREGRESSIVE PREDICTION\n",
    "# ===============================\n",
    "def predict_autoregressive(\n",
    "    model, image, mech_idx, max_seq_len, device,\n",
    "    temperature=1.0, top_k=None\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        decoder_input = torch.tensor([[SOS_TOKEN]], device=device, dtype=torch.long)\n",
    "        mech_labels = torch.tensor([mech_idx], device=device, dtype=torch.long)\n",
    "\n",
    "        for step in range(max_seq_len):\n",
    "            T = decoder_input.size(1)\n",
    "            causal_mask = torch.tril(torch.ones(T, T, device=device)).bool()\n",
    "\n",
    "            logits = model(decoder_input, causal_mask, image, mech_labels)\n",
    "            next_logits = logits[:, -1, :] / max(temperature, 1e-6)\n",
    "            probs = F.softmax(next_logits, dim=-1)\n",
    "\n",
    "            if top_k is not None and top_k > 0:\n",
    "                k = min(int(top_k), probs.size(-1))\n",
    "                topk_probs, topk_idx = torch.topk(probs, k=k, dim=-1)\n",
    "                next_token = topk_idx.gather(-1, torch.multinomial(topk_probs, 1))\n",
    "            elif temperature == 0:\n",
    "                next_token = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "            else:\n",
    "                next_token = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            token = int(next_token.item())\n",
    "            decoder_input = torch.cat([decoder_input, next_token], dim=1)\n",
    "            if token == EOS_TOKEN:\n",
    "                break\n",
    "\n",
    "    return decoder_input.squeeze(0).cpu().numpy()\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# MAIN LOOP\n",
    "# ===============================\n",
    "print(\"Starting conditional coupler curve generation...\")\n",
    "os.makedirs(\"results_coupler\", exist_ok=True)\n",
    "\n",
    "for i, batch in enumerate(tqdm(dataloader, total=MAX_SAMPLES, desc=\"Simulating\")):\n",
    "    if i >= MAX_SAMPLES:\n",
    "        break\n",
    "\n",
    "    image = batch[\"images\"].to(device)\n",
    "    gt_tokens = batch[\"labels_discrete\"][0].numpy()\n",
    "\n",
    "    # âœ… Get GT mech type\n",
    "    gt_mech_idx = int(batch[\"encoded_labels\"][0].item())\n",
    "    gt_mech_name = index_to_label.get(str(gt_mech_idx), \"UNKNOWN\")\n",
    "\n",
    "    # --- Ground Truth coordinates ---\n",
    "    gt_coord_tokens = [t for t in gt_tokens if t >= BIN_OFFSET]\n",
    "    if len(gt_coord_tokens) < 4:\n",
    "        continue\n",
    "    gt_coords_tensor = torch.tensor(gt_coord_tokens) - BIN_OFFSET\n",
    "    gt_coords_float = binner.bin_to_value_torch(gt_coords_tensor).cpu().numpy()\n",
    "    if gt_coords_float.size % 2 == 1:\n",
    "        gt_coords_float = gt_coords_float[:-1]\n",
    "    gt_points = gt_coords_float.reshape(-1, 2)\n",
    "\n",
    "    # Create subfolder for this sample\n",
    "    sample_dir = f\"results_coupler/sample_{i:03d}_{gt_mech_name}\"\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "\n",
    "    # ==========================================================\n",
    "    # ðŸ–¼ï¸ SAVE INPUT COUPLER IMAGE\n",
    "    # ==========================================================\n",
    "    img = image[0].detach().cpu()  # (C, H, W)\n",
    "    if img.ndim == 3:\n",
    "        if img.shape[0] == 1:\n",
    "            img_np = img.squeeze(0).numpy()\n",
    "            plt.imshow(img_np, cmap=\"gray\")\n",
    "        else:\n",
    "            img_np = img.permute(1, 2, 0).numpy()\n",
    "            img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min() + 1e-8)\n",
    "            plt.imshow(img_np)\n",
    "    else:\n",
    "        plt.imshow(img.numpy(), cmap=\"gray\")\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Input Coupler Curve â€” {gt_mech_name}\")\n",
    "    input_path = os.path.join(sample_dir, \"input_curve.png\")\n",
    "    plt.savefig(input_path, bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close()\n",
    "    print(f\"ðŸ–¼ï¸ Saved input coupler image: {input_path}\")\n",
    "\n",
    "    # --- Simulate GT coupler ---\n",
    "    ex_gt = {\n",
    "        \"params\": gt_points.tolist(),\n",
    "        \"type\": gt_mech_name,\n",
    "        \"speedScale\": speedscale,\n",
    "        \"steps\": steps,\n",
    "        \"relativeTolerance\": 0.1,\n",
    "    }\n",
    "    try:\n",
    "        temp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps([ex_gt])).json()\n",
    "        P = np.array(temp[0][\"poses\"]) if isinstance(temp, list) and temp and \"poses\" in temp[0] else None\n",
    "    except Exception as e:\n",
    "        print(f\"GT sim failed: {e}\")\n",
    "        continue\n",
    "\n",
    "    if P is None or P.shape[0] < minsteps:\n",
    "        continue\n",
    "\n",
    "    coup_idx_gt = coupler_index_for(gt_mech_name)\n",
    "    if coup_idx_gt < 0:\n",
    "        continue\n",
    "    original_x, original_y = P[:, coup_idx_gt, 0], P[:, coup_idx_gt, 1]\n",
    "    orig_phi = -get_pca_inclination(original_x, original_y)\n",
    "    orig_denom = np.sqrt(np.var(original_x) + np.var(original_y)) + 1e-8\n",
    "    ox_mean, oy_mean = np.mean(original_x), np.mean(original_y)\n",
    "\n",
    "    print(f\"\\n=== Sample {i} | GT={gt_mech_name} ===\")\n",
    "    print(\"GT joint positions:\")\n",
    "    for j, (x, y) in enumerate(gt_points):\n",
    "        print(f\"  J{j}: ({x:.3f}, {y:.3f})\")\n",
    "\n",
    "    # --- Generate predictions for each mechanism type ---\n",
    "    for mech_idx in range(NUM_MECH_TYPES):\n",
    "        mech_name = index_to_label.get(str(mech_idx), f\"mech_{mech_idx}\")\n",
    "        print(f\"\\n=== Predicting for mech: {mech_name} (idx={mech_idx}) ===\")\n",
    "\n",
    "        pred_tokens = predict_autoregressive(\n",
    "            model,\n",
    "            image,\n",
    "            mech_idx,\n",
    "            model_config[\"tgt_seq_len\"],\n",
    "            device,\n",
    "            temperature=0.0,\n",
    "            top_k=0,\n",
    "        )\n",
    "\n",
    "        coord_tokens = [t for t in pred_tokens if t >= BIN_OFFSET]\n",
    "        if len(coord_tokens) < 4:\n",
    "            continue\n",
    "        coords_tensor = torch.tensor(coord_tokens) - BIN_OFFSET\n",
    "        coords_float = binner.bin_to_value_torch(coords_tensor).cpu().numpy()\n",
    "        if coords_float.size % 2 == 1:\n",
    "            coords_float = coords_float[:-1]\n",
    "        pred_points = coords_float.reshape(-1, 2)\n",
    "\n",
    "        print(f\"Pred joint positions for {mech_name}:\")\n",
    "        for j, (x, y) in enumerate(pred_points):\n",
    "            print(f\"  J{j}: ({x:.3f}, {y:.3f})\")\n",
    "\n",
    "        # --- Simulate predicted coupler ---\n",
    "        ex_pred = {\n",
    "            \"params\": pred_points.tolist(),\n",
    "            \"type\": mech_name,\n",
    "            \"speedScale\": speedscale,\n",
    "            \"steps\": steps,\n",
    "            \"relativeTolerance\": 0.1,\n",
    "        }\n",
    "        try:\n",
    "            temp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps([ex_pred])).json()\n",
    "            Pp = np.array(temp[0][\"poses\"]) if isinstance(temp, list) and temp and \"poses\" in temp[0] else None\n",
    "        except Exception as e:\n",
    "            print(f\"Pred sim failed for {mech_name}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if Pp is None or P.shape[0] < minsteps:\n",
    "            continue\n",
    "\n",
    "        coup_idx_pred = coupler_index_for(mech_name)\n",
    "        if coup_idx_pred < 0:\n",
    "            continue\n",
    "        generated_x, generated_y = Pp[:, coup_idx_pred, 0], Pp[:, coup_idx_pred, 1]\n",
    "        if np.isnan(generated_x).any() or np.isinf(generated_x).any():\n",
    "            continue\n",
    "\n",
    "        # --- Align predicted to GT ---\n",
    "        gen_phi = -get_pca_inclination(generated_x, generated_y)\n",
    "        rotation = gen_phi - orig_phi\n",
    "        generated_x, generated_y = rotate_curve(generated_x, generated_y, rotation)\n",
    "        gen_denom = np.sqrt(np.var(generated_x) + np.var(generated_y)) + 1e-8\n",
    "        scale = orig_denom / gen_denom\n",
    "        generated_x *= scale\n",
    "        generated_y *= scale\n",
    "        gx_mean, gy_mean = np.mean(generated_x), np.mean(generated_y)\n",
    "        generated_x -= (gx_mean - ox_mean)\n",
    "        generated_y -= (gy_mean - oy_mean)\n",
    "\n",
    "        # --- Plot ---\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.plot(original_x, original_y, \"r-\", label=f\"GT Coupler ({gt_mech_name})\")\n",
    "        plt.plot(generated_x, generated_y, \"g--\", label=f\"Pred Coupler ({mech_name})\")\n",
    "\n",
    "        plt.scatter(gt_points[:, 0], gt_points[:, 1], color=\"red\", s=40, zorder=5)\n",
    "        for j, (x, y) in enumerate(gt_points):\n",
    "            plt.text(x, y, f\"J{j}\", color=\"red\", fontsize=9, weight=\"bold\")\n",
    "\n",
    "        plt.scatter(pred_points[:, 0], pred_points[:, 1], color=\"green\", s=40, zorder=5)\n",
    "        for j, (x, y) in enumerate(pred_points):\n",
    "            plt.text(x, y, f\"J{j}\", color=\"green\", fontsize=9, weight=\"bold\")\n",
    "\n",
    "        plt.axis(\"equal\")\n",
    "        plt.legend()\n",
    "        plt.title(f\"Sample {i} | GT={gt_mech_name} | Pred={mech_name}\")\n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(sample_dir, f\"mech_{mech_name}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "        print(f\"âœ… Saved: {save_path}\")\n",
    "\n",
    "print(\"âœ… Finished all mechanism variations.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
