{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746bb70-eb1f-473e-bc2b-97abcf5067f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from llama_latent_model import LatentLLaMA_SingleToken\n",
    "from dataset import BarLinkageDataset \n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "from dataset_generation.curve_plot import get_pca_inclination, rotate_curve\n",
    "import scipy.spatial.distance as sciDist\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354fc90-9448-4531-ad0b-f95058e8fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headless simulator version\n",
    "index = 0 # local server index \n",
    "API_ENDPOINT = f\"http://localhost:4000/simulation\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "speedscale = 1\n",
    "steps = 360\n",
    "minsteps = int(steps*20/360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8ae72c-963c-458f-a536-c6737e88084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./weights/CE_GAUS_MSE/LATENT_LLAMA_d1024_h32_n6_bs512_lr0.0005_best.pth\"\n",
    "data_dir = \"/home/anurizada/Documents/processed_dataset_17\"\n",
    "batch_size = 1\n",
    "\n",
    "dataset = BarLinkageDataset(data_dir=data_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4913484-58cd-4236-bc77-e3cf855f884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model_config = checkpoint['model_config']\n",
    "\n",
    "# Initialize model\n",
    "model = LatentLLaMA_SingleToken(\n",
    "    tgt_seq_len=model_config['tgt_seq_len'],\n",
    "    d_model=model_config['d_model'],\n",
    "    h=model_config['h'],\n",
    "    N=model_config['N'],\n",
    "    num_labels=model_config['num_labels'],\n",
    "    vocab_size=model_config['vocab_size'],\n",
    "    latent_dim=model_config['latent_dim']).to(device)\n",
    "\n",
    "# Load weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# ---------------------------\n",
    "# Count parameters\n",
    "# ---------------------------\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    non_trainable_params = total_params - trainable_params\n",
    "\n",
    "    print(\"\\nðŸ§® Model Parameter Summary\")\n",
    "    print(f\"Total parameters:     {total_params:,}  ({total_params/1e6:.2f} M)\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}  ({trainable_params/1e6:.2f} M)\")\n",
    "    print(f\"Frozen parameters:    {non_trainable_params:,}  ({non_trainable_params/1e6:.2f} M)\")\n",
    "    return total_params, trainable_params, non_trainable_params\n",
    "\n",
    "# Run the counter\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ad52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "MAX_SAMPLES = 100\n",
    "SOS_TOKEN, EOS_TOKEN, PAD_TOKEN = 0, 1, 2\n",
    "NUM_SPECIAL_TOKENS = 3\n",
    "NUM_MECH_TYPES = 17\n",
    "BIN_OFFSET = NUM_SPECIAL_TOKENS\n",
    "NUM_BINS = 201            # must match training\n",
    "LATENT_DIM = 50           # must match training\n",
    "\n",
    "label_mapping_path = \"/home/anurizada/Documents/processed_dataset_17/label_mapping.json\"\n",
    "coupler_mapping_path = \"/home/anurizada/Documents/transformer/BSIdict.json\"\n",
    "\n",
    "with open(label_mapping_path, \"r\") as f:\n",
    "    label_mapping = json.load(f)\n",
    "index_to_label = label_mapping[\"index_to_label\"]\n",
    "\n",
    "with open(coupler_mapping_path, \"r\") as f:\n",
    "    coupler_mapping = json.load(f)\n",
    "\n",
    "\n",
    "def coupler_index_for(mech_type: str) -> int:\n",
    "    \"\"\"Return coupler curve index from BSIdict.json.\"\"\"\n",
    "    if mech_type in coupler_mapping and \"c\" in coupler_mapping[mech_type]:\n",
    "        cvec = coupler_mapping[mech_type][\"c\"]\n",
    "        if isinstance(cvec, list) and 1 in cvec:\n",
    "            return cvec.index(1)\n",
    "    return -1\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Helper: safe + short names for filesystem paths\n",
    "# ---------------------------------------------------------\n",
    "def safe_name(name: str, max_len: int = 30) -> str:\n",
    "    chars = []\n",
    "    for c in name:\n",
    "        if c.isalnum():\n",
    "            chars.append(c)\n",
    "        else:\n",
    "            chars.append(\"_\")\n",
    "    sanitized = \"\".join(chars)\n",
    "    if len(sanitized) > max_len:\n",
    "        sanitized = sanitized[:max_len]\n",
    "    return sanitized or \"unk\"\n",
    "\n",
    "\n",
    "def temp_to_str(t: float) -> str:\n",
    "    s = f\"{t:.2f}\".rstrip(\"0\").rstrip(\".\")\n",
    "    s = s.replace(\".\", \"p\").replace(\"-\", \"m\")\n",
    "    return s or \"0\"\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# CoordinateBinner (same as training)\n",
    "# =========================================================\n",
    "class CoordinateBinner:\n",
    "    def __init__(self, kappa=1.0, num_bins=200):\n",
    "        self.kappa = kappa\n",
    "        self.num_bins = num_bins\n",
    "        self.bin_edges = np.linspace(-kappa, kappa, num_bins + 1)\n",
    "        self.bin_centers = (self.bin_edges[:-1] + self.bin_edges[1:]) / 2\n",
    "\n",
    "    def bin_to_value_torch(self, bin_index_tensor):\n",
    "        bin_index_tensor = torch.clamp(bin_index_tensor, 0, self.num_bins - 1)\n",
    "        bin_centers_tensor = torch.tensor(\n",
    "            self.bin_centers, device=bin_index_tensor.device, dtype=torch.float32\n",
    "        )\n",
    "        return bin_centers_tensor[bin_index_tensor]\n",
    "\n",
    "\n",
    "binner = CoordinateBinner(kappa=1.0, num_bins=NUM_BINS - 1)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Causal mask builder\n",
    "# =========================================================\n",
    "def build_causal_mask(seq_len: int, device: torch.device):\n",
    "    mask = torch.tril(torch.ones(seq_len, seq_len, device=device, dtype=torch.bool))\n",
    "    return mask.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# AUTOREGRESSIVE PREDICTION (Latent LLaMA)\n",
    "# =========================================================\n",
    "def predict_autoregressive_latent(\n",
    "    model,\n",
    "    latent,\n",
    "    mech_idx: int,\n",
    "    max_seq_len: int,\n",
    "    device,\n",
    "    temperature: float = 1.0,\n",
    "    top_k: int | None = None,\n",
    "    eos_token: int = EOS_TOKEN,\n",
    "    sos_token: int = SOS_TOKEN,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    if latent.dim() == 1:\n",
    "        latent = latent.unsqueeze(0)\n",
    "\n",
    "    latent = latent.to(device)\n",
    "    mech_labels = torch.tensor([mech_idx], device=device, dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        decoder_input = torch.tensor([[sos_token]], device=device, dtype=torch.long)\n",
    "\n",
    "        for step in range(max_seq_len):\n",
    "            seq_len = decoder_input.size(1)\n",
    "            causal_mask = build_causal_mask(seq_len, device)\n",
    "\n",
    "            logits = model(\n",
    "                decoder_input,\n",
    "                causal_mask,\n",
    "                latent,\n",
    "                mech_labels,\n",
    "            )\n",
    "\n",
    "            next_logits = logits[:, -1, :] / max(temperature, 1e-6)\n",
    "            probs = F.softmax(next_logits, dim=-1)\n",
    "\n",
    "            # ----------------------------------------\n",
    "            # TOP-K sampling\n",
    "            # ----------------------------------------\n",
    "            if top_k is not None and top_k > 0:\n",
    "                k = min(int(top_k), probs.size(-1))\n",
    "                topk_probs, topk_idx = torch.topk(probs, k=k, dim=-1)\n",
    "                next_token = topk_idx.gather(-1, torch.multinomial(topk_probs, 1))\n",
    "\n",
    "            elif temperature == 0:\n",
    "                next_token = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "\n",
    "            else:\n",
    "                next_token = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            token = int(next_token.item())\n",
    "            decoder_input = torch.cat([decoder_input, next_token], dim=1)\n",
    "\n",
    "            if token == eos_token:\n",
    "                break\n",
    "\n",
    "    return decoder_input.squeeze(0).cpu().numpy()\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# MAIN LOOP\n",
    "# =========================================================\n",
    "\n",
    "tgt_seq_len = model_config[\"tgt_seq_len\"]\n",
    "\n",
    "print(\"Starting conditional coupler curve generation (latent-based)...\")\n",
    "os.makedirs(\"results_coupler_latent\", exist_ok=True)\n",
    "\n",
    "for i, batch in enumerate(tqdm(dataloader, total=min(MAX_SAMPLES, len(dataset)), desc=\"Simulating\")):\n",
    "    if i >= MAX_SAMPLES:\n",
    "        break\n",
    "\n",
    "    # --- Latent input ---\n",
    "    latents = batch[\"vae_mu\"].to(device).squeeze(-1)\n",
    "    latent = latents[0]\n",
    "\n",
    "    # --- GT ---\n",
    "    gt_tokens = batch[\"labels_discrete\"][0].numpy()\n",
    "    gt_mech_idx = int(batch[\"encoded_labels\"][0].item())\n",
    "    gt_mech_name = index_to_label.get(str(gt_mech_idx), \"UNKNOWN\")\n",
    "    gt_mech_name_safe = safe_name(gt_mech_name)\n",
    "\n",
    "    # --- Save input image ---\n",
    "    sample_dir = f\"results_coupler_latent/sample_{i:03d}_{gt_mech_name_safe}\"\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "\n",
    "    if \"images\" in batch:\n",
    "        img_np = batch[\"images\"][0].detach().cpu().squeeze().numpy()\n",
    "        plt.imsave(os.path.join(sample_dir, \"input_image.png\"), img_np, cmap=\"gray\")\n",
    "\n",
    "    # --- Ground Truth coords ---\n",
    "    gt_coord_tokens = [t for t in gt_tokens if t >= BIN_OFFSET]\n",
    "    if len(gt_coord_tokens) < 4:\n",
    "        continue\n",
    "\n",
    "    gt_coords_tensor = torch.tensor(gt_coord_tokens) - BIN_OFFSET\n",
    "    gt_coords_float = binner.bin_to_value_torch(gt_coords_tensor.to(device)).cpu().numpy()\n",
    "\n",
    "    if gt_coords_float.size % 2 == 1:\n",
    "        gt_coords_float = gt_coords_float[:-1]\n",
    "    gt_points = gt_coords_float.reshape(-1, 2)\n",
    "\n",
    "    # --- Simulate GT ---\n",
    "    ex_gt = {\n",
    "        \"params\": gt_points.tolist(),\n",
    "        \"type\": gt_mech_name,\n",
    "        \"speedScale\": speedscale,\n",
    "        \"steps\": steps,\n",
    "        \"relativeTolerance\": 0.1,\n",
    "    }\n",
    "    try:\n",
    "        temp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps([ex_gt])).json()\n",
    "        P = np.array(temp[0][\"poses\"]) if isinstance(temp, list) and temp and \"poses\" in temp[0] else None\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    if P is None or P.shape[0] < minsteps:\n",
    "        continue\n",
    "\n",
    "    coup_idx_gt = coupler_index_for(gt_mech_name)\n",
    "    if coup_idx_gt < 0:\n",
    "        continue\n",
    "\n",
    "    original_x, original_y = P[:, coup_idx_gt, 0], P[:, coup_idx_gt, 1]\n",
    "    orig_phi = -get_pca_inclination(original_x, original_y)\n",
    "    orig_denom = np.sqrt(np.var(original_x) + np.var(original_y)) + 1e-8\n",
    "    ox_mean, oy_mean = np.mean(original_x), np.mean(original_y)\n",
    "\n",
    "    all_predicted_points: dict[str, np.ndarray] = {}\n",
    "\n",
    "    # ============================================================\n",
    "    # Temperature Ã— Top-K Sweep\n",
    "    # ============================================================\n",
    "\n",
    "    temperatures = [0.0, 0.5, 1.0, 1.5, 2.0]\n",
    "    top_k_values = [1, 5, 10, 20]\n",
    "\n",
    "    for mech_idx in range(NUM_MECH_TYPES):\n",
    "\n",
    "        mech_name = index_to_label.get(str(mech_idx), f\"mech_{mech_idx}\")\n",
    "        mech_name_safe = safe_name(mech_name)\n",
    "\n",
    "        for temp in temperatures:\n",
    "            temp_str = temp_to_str(temp)\n",
    "\n",
    "            for top_k in top_k_values:\n",
    "\n",
    "                pred_tokens = predict_autoregressive_latent(\n",
    "                    model=model,\n",
    "                    latent=latent,\n",
    "                    mech_idx=mech_idx,\n",
    "                    max_seq_len=tgt_seq_len,\n",
    "                    device=device,\n",
    "                    temperature=temp,\n",
    "                    top_k=top_k,        # <--- TOP-K ENABLED\n",
    "                )\n",
    "\n",
    "                coord_tokens = [t for t in pred_tokens if t >= BIN_OFFSET]\n",
    "                if len(coord_tokens) < 4:\n",
    "                    continue\n",
    "\n",
    "                coords_tensor = torch.tensor(coord_tokens, device=device) - BIN_OFFSET\n",
    "                coords_float = binner.bin_to_value_torch(coords_tensor).cpu().numpy()\n",
    "\n",
    "                if coords_float.size % 2 == 1:\n",
    "                    coords_float = coords_float[:-1]\n",
    "\n",
    "                pred_points = coords_float.reshape(-1, 2)\n",
    "                key = f\"{mech_name_safe}_t{temp_str}_k{top_k}\"\n",
    "                all_predicted_points[key] = pred_points\n",
    "\n",
    "                # --- Simulate predicted ---\n",
    "                ex_pred = {\n",
    "                    \"params\": pred_points.tolist(),\n",
    "                    \"type\": mech_name,\n",
    "                    \"speedScale\": speedscale,\n",
    "                    \"steps\": steps,\n",
    "                    \"relativeTolerance\": 0.1,\n",
    "                }\n",
    "                try:\n",
    "                    temp_resp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps([ex_pred])).json()\n",
    "                    Pp = np.array(temp_resp[0][\"poses\"]) if isinstance(temp_resp, list) and temp_resp and \"poses\" in temp_resp[0] else None\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                if Pp is None or Pp.shape[0] < minsteps:\n",
    "                    continue\n",
    "\n",
    "                coup_idx_pred = coupler_index_for(mech_name)\n",
    "                if coup_idx_pred < 0:\n",
    "                    continue\n",
    "\n",
    "                generated_x, generated_y = Pp[:, coup_idx_pred, 0], Pp[:, coup_idx_pred, 1]\n",
    "                if np.isnan(generated_x).any() or np.isinf(generated_x).any():\n",
    "                    continue\n",
    "\n",
    "                # --- Align predicted coupler ---\n",
    "                gen_phi = -get_pca_inclination(generated_x, generated_y)\n",
    "                rotation = gen_phi - orig_phi\n",
    "                generated_x, generated_y = rotate_curve(generated_x, generated_y, rotation)\n",
    "\n",
    "                gen_denom = np.sqrt(np.var(generated_x) + np.var(generated_y)) + 1e-8\n",
    "                scale = orig_denom / gen_denom\n",
    "                generated_x *= scale\n",
    "                generated_y *= scale\n",
    "\n",
    "                gx_mean, gy_mean = np.mean(generated_x), np.mean(generated_y)\n",
    "                generated_x -= (gx_mean - ox_mean)\n",
    "                generated_y -= (gy_mean - oy_mean)\n",
    "\n",
    "                # --- Plot ---\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.plot(original_x, original_y, \"r-\", label=f\"GT Coupler ({gt_mech_name})\")\n",
    "                plt.plot(generated_x, generated_y, \"g--\", label=f\"Pred ({mech_name}) t={temp} k={top_k}\")\n",
    "                plt.scatter(gt_points[:, 0], gt_points[:, 1], color=\"red\", s=40)\n",
    "                plt.scatter(pred_points[:, 0], pred_points[:, 1], color=\"green\", s=40)\n",
    "                plt.axis(\"equal\")\n",
    "                plt.legend()\n",
    "                plt.title(f\"Sample {i} | GT={gt_mech_name} | Pred={mech_name} | t={temp} k={top_k}\")\n",
    "                plt.tight_layout()\n",
    "\n",
    "                save_fname = f\"mech_{mech_name_safe}_t{temp_str}_k{top_k}.png\"\n",
    "                save_path = os.path.join(sample_dir, save_fname)\n",
    "                plt.savefig(save_path)\n",
    "                plt.close()\n",
    "\n",
    "    # ============================================================\n",
    "    # Combined joint prediction scatter plot\n",
    "    # ============================================================\n",
    "    if len(all_predicted_points) == 0:\n",
    "        continue\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(\n",
    "        gt_points[:, 0],\n",
    "        gt_points[:, 1],\n",
    "        c=\"red\",\n",
    "        s=80,\n",
    "        edgecolor=\"black\",\n",
    "        label=f\"GT ({gt_mech_name})\",\n",
    "        zorder=6,\n",
    "    )\n",
    "\n",
    "    for j, (x, y) in enumerate(gt_points):\n",
    "        plt.text(x + 0.005, y + 0.005, f\"{j}\", color=\"red\", fontsize=9)\n",
    "\n",
    "    max_joints = max(pts.shape[0] for pts in all_predicted_points.values())\n",
    "    cmap = plt.cm.get_cmap(\"tab10\", max_joints)\n",
    "\n",
    "    for mech_name_key, pts in all_predicted_points.items():\n",
    "        num_joints = pts.shape[0]\n",
    "        for j in range(num_joints):\n",
    "            color = cmap(j % max_joints)\n",
    "            plt.scatter(pts[j, 0], pts[j, 1], color=color, s=30, alpha=0.8)\n",
    "            plt.text(pts[j, 0] + 0.002, pts[j, 1] + 0.002, str(j), fontsize=7, color=color)\n",
    "\n",
    "    plt.title(f\"Predicted Joint Positions â€” Sample {i} (GT={gt_mech_name})\")\n",
    "    plt.xlabel(\"X coordinate\")\n",
    "    plt.ylabel(\"Y coordinate\")\n",
    "    plt.axis(\"equal\")\n",
    "\n",
    "    handles = [\n",
    "        plt.Line2D([0], [0], marker=\"o\", color=\"w\", markerfacecolor=cmap(j), label=f\"Joint {j}\")\n",
    "        for j in range(max_joints)\n",
    "    ]\n",
    "    plt.legend(handles=handles, fontsize=7, loc=\"upper right\", ncol=2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    joint_scatter_path = os.path.join(sample_dir, \"all_predicted_joints_colored.png\")\n",
    "    plt.savefig(joint_scatter_path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"âœ… Saved: {joint_scatter_path}\")\n",
    "\n",
    "print(\"âœ… Finished all mechanism variations (latent-based).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
