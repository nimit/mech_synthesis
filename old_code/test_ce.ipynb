{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746bb70-eb1f-473e-bc2b-97abcf5067f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from model import SingleImageTransformer\n",
    "from dataset import BarLinkageDataset \n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "from dataset_generation.curve_plot import get_pca_inclination, rotate_curve\n",
    "import scipy.spatial.distance as sciDist\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354fc90-9448-4531-ad0b-f95058e8fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headless simulator version\n",
    "index = 0 # local server index \n",
    "API_ENDPOINT = f\"http://localhost:4000/simulation\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "speedscale = 1\n",
    "steps = 360\n",
    "minsteps = int(steps*20/360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8ae72c-963c-458f-a536-c6737e88084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"weights/transformer_weights_CE/d1024_h32_n6_bs512_lr0.0001_best.pth\"\n",
    "data_dir = \"/home/anurizada/Documents/processed_dataset\"\n",
    "batch_size = 1\n",
    "\n",
    "dataset = BarLinkageDataset(data_dir=data_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4913484-58cd-4236-bc77-e3cf855f884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model_config = checkpoint['model_config']\n",
    "\n",
    "# Initialize model\n",
    "model = SingleImageTransformer(\n",
    "    tgt_seq_len=model_config['tgt_seq_len'],\n",
    "    d_model=model_config['d_model'],\n",
    "    h=model_config['h'],\n",
    "    N=model_config['N'],\n",
    "    num_labels=model_config['num_labels'],\n",
    "    vocab_size=model_config['vocab_size'],\n",
    ").to(device)\n",
    "\n",
    "# Load weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ad52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "MAX_SAMPLES = 5\n",
    "TEMPERATURES = [0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
    "\n",
    "SOS_TOKEN, EOS_TOKEN, PAD_TOKEN = 0, 1, 2\n",
    "NUM_SPECIAL_TOKENS = 3\n",
    "NUM_MECH_TYPES = 17\n",
    "BIN_OFFSET = NUM_SPECIAL_TOKENS + NUM_MECH_TYPES  # = 20\n",
    "\n",
    "# Define externally:\n",
    "# API_ENDPOINT, HEADERS, speedscale, steps, minsteps\n",
    "\n",
    "label_mapping_path = \"/home/anurizada/Documents/processed_dataset/label_mapping.json\"\n",
    "coupler_mapping_path = \"/home/anurizada/Documents/transformer/BSIdict.json\"\n",
    "\n",
    "with open(label_mapping_path, \"r\") as f:\n",
    "    label_mapping = json.load(f)\n",
    "index_to_label = label_mapping[\"index_to_label\"]\n",
    "\n",
    "with open(coupler_mapping_path, \"r\") as f:\n",
    "    coupler_mapping = json.load(f)\n",
    "\n",
    "def coupler_index_for(mech_type: str) -> int:\n",
    "    \"\"\"Return coupler curve index from BSIdict.json.\"\"\"\n",
    "    if mech_type in coupler_mapping and \"c\" in coupler_mapping[mech_type]:\n",
    "        cvec = coupler_mapping[mech_type][\"c\"]\n",
    "        if isinstance(cvec, list) and 1 in cvec:\n",
    "            return cvec.index(1)\n",
    "    return -1\n",
    "\n",
    "# ===============================\n",
    "# BINNER\n",
    "# ===============================\n",
    "class CoordinateBinner:\n",
    "    def __init__(self, kappa=1.0, num_bins=200):\n",
    "        self.kappa = kappa\n",
    "        self.num_bins = num_bins\n",
    "        self.bin_edges = np.linspace(-kappa, kappa, num_bins + 1)\n",
    "        self.bin_centers = (self.bin_edges[:-1] + self.bin_edges[1:]) / 2\n",
    "\n",
    "    def bin_to_value_torch(self, bin_index_tensor):\n",
    "        bin_index_tensor = torch.clamp(bin_index_tensor, 0, self.num_bins - 1)\n",
    "        device = bin_index_tensor.device\n",
    "        bin_centers_tensor = torch.tensor(self.bin_centers, device=device, dtype=torch.float32)\n",
    "        return bin_centers_tensor[bin_index_tensor]\n",
    "\n",
    "binner = CoordinateBinner(kappa=1.0, num_bins=201)\n",
    "\n",
    "# ===============================\n",
    "# AUTOREGRESSIVE PREDICTION\n",
    "# ===============================\n",
    "def predict_autoregressive(model, image, max_seq_len, device, temperature=1.0, top_k=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        decoder_input = torch.tensor([[SOS_TOKEN]], device=device, dtype=torch.long)\n",
    "        for _ in range(max_seq_len):\n",
    "            T = decoder_input.size(1)\n",
    "            causal_mask = torch.tril(torch.ones(T, T, device=device)).bool()\n",
    "\n",
    "            logits = model(decoder_input, causal_mask, image, None)\n",
    "            next_logits = logits[:, -1, :] / float(temperature)\n",
    "            probs = F.softmax(next_logits, dim=-1)\n",
    "\n",
    "            if top_k is None:\n",
    "                next_token = torch.argmax(probs, dim=-1)\n",
    "            else:\n",
    "                k = min(int(top_k), probs.size(-1))\n",
    "                topk_probs, topk_idx = torch.topk(probs, k=k, dim=-1)\n",
    "                sampled = torch.multinomial(topk_probs, num_samples=1)\n",
    "                next_token = topk_idx.gather(-1, sampled).squeeze(1)\n",
    "\n",
    "            token = int(next_token.item())\n",
    "            decoder_input = torch.cat([decoder_input, next_token.unsqueeze(1)], dim=1)\n",
    "            if token == EOS_TOKEN:\n",
    "                break\n",
    "    return decoder_input.squeeze(0).cpu().numpy()\n",
    "\n",
    "# ===============================\n",
    "# MAIN LOOP\n",
    "# ===============================\n",
    "print(\"Starting multi-temperature coupler curve generation...\")\n",
    "os.makedirs(\"results_coupler\", exist_ok=True)\n",
    "\n",
    "for i, batch in enumerate(tqdm(dataloader, total=MAX_SAMPLES, desc=\"Simulating\")):\n",
    "    if i >= MAX_SAMPLES:\n",
    "        break\n",
    "\n",
    "    image = batch[\"images\"].to(device)\n",
    "    gt_tokens = batch[\"labels_discrete\"][0].numpy()\n",
    "\n",
    "    # --- Ground Truth ---\n",
    "    gt_mech_idx = gt_tokens[0] - NUM_SPECIAL_TOKENS\n",
    "    gt_mech_name = index_to_label.get(str(gt_mech_idx), \"UNKNOWN\")\n",
    "    gt_coord_tokens = [t for t in gt_tokens[1:] if t >= BIN_OFFSET]\n",
    "    if len(gt_coord_tokens) < 4:\n",
    "        continue\n",
    "    gt_coords_tensor = torch.tensor(gt_coord_tokens) - BIN_OFFSET\n",
    "    gt_coords_float = binner.bin_to_value_torch(gt_coords_tensor).cpu().numpy()\n",
    "    if gt_coords_float.size % 2 == 1:\n",
    "        gt_coords_float = gt_coords_float[:-1]\n",
    "    gt_points = gt_coords_float.reshape(-1, 2)\n",
    "\n",
    "    # Create subfolder for this sample\n",
    "    sample_dir = f\"results_coupler/sample_{i:03d}_{gt_mech_name}\"\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "\n",
    "    # --- Simulate GT coupler ---\n",
    "    ex_gt = {\n",
    "        \"params\": gt_points.tolist(),\n",
    "        \"type\": gt_mech_name,\n",
    "        \"speedScale\": speedscale,\n",
    "        \"steps\": steps,\n",
    "        \"relativeTolerance\": 0.1,\n",
    "    }\n",
    "    try:\n",
    "        temp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps([ex_gt])).json()\n",
    "        P = np.array(temp[0][\"poses\"]) if isinstance(temp, list) and temp and \"poses\" in temp[0] else None\n",
    "    except Exception as e:\n",
    "        print(f\"GT sim failed: {e}\")\n",
    "        continue\n",
    "    if P is None or P.shape[0] < minsteps:\n",
    "        continue\n",
    "\n",
    "    coup_idx_gt = coupler_index_for(gt_mech_name)\n",
    "    if coup_idx_gt < 0:\n",
    "        continue\n",
    "    original_x, original_y = P[:, coup_idx_gt, 0], P[:, coup_idx_gt, 1]\n",
    "    orig_phi = -get_pca_inclination(original_x, original_y)\n",
    "    orig_denom = np.sqrt(np.var(original_x) + np.var(original_y)) + 1e-8\n",
    "    ox_mean, oy_mean = np.mean(original_x), np.mean(original_y)\n",
    "\n",
    "    print(f\"\\n=== Sample {i} | GT={gt_mech_name} ===\")\n",
    "    print(\"GT joint positions:\")\n",
    "    for j, (x, y) in enumerate(gt_points):\n",
    "        print(f\"  J{j}: ({x:.3f}, {y:.3f})\")\n",
    "\n",
    "    # --- Multiple Predictions (different temperatures) ---\n",
    "    for temp_val in TEMPERATURES:\n",
    "        pred_tokens = predict_autoregressive(model, image, model_config[\"tgt_seq_len\"], device, temperature=temp_val, top_k=32)\n",
    "        mech_idx = pred_tokens[1] - NUM_SPECIAL_TOKENS if len(pred_tokens) > 1 else -1\n",
    "        mech_name = index_to_label.get(str(mech_idx), \"UNKNOWN\")\n",
    "\n",
    "        coord_tokens = [t for t in pred_tokens if t >= BIN_OFFSET]\n",
    "        if len(coord_tokens) < 4:\n",
    "            continue\n",
    "        coords_tensor = torch.tensor(coord_tokens) - BIN_OFFSET\n",
    "        coords_float = binner.bin_to_value_torch(coords_tensor).cpu().numpy()\n",
    "        if coords_float.size % 2 == 1:\n",
    "            coords_float = coords_float[:-1]\n",
    "        pred_points = coords_float.reshape(-1, 2)\n",
    "\n",
    "        print(f\"\\n[Temp={temp_val:.1f}] Pred mech: {mech_name}\")\n",
    "        print(\"Pred joint positions:\")\n",
    "        for j, (x, y) in enumerate(pred_points):\n",
    "            print(f\"  J{j}: ({x:.3f}, {y:.3f})\")\n",
    "\n",
    "        # --- Simulate predicted coupler ---\n",
    "        ex_pred = {\n",
    "            \"params\": pred_points.tolist(),\n",
    "            \"type\": mech_name,\n",
    "            \"speedScale\": speedscale,\n",
    "            \"steps\": steps,\n",
    "            \"relativeTolerance\": 0.1,\n",
    "        }\n",
    "        try:\n",
    "            temp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps([ex_pred])).json()\n",
    "            Pp = np.array(temp[0][\"poses\"]) if isinstance(temp, list) and temp and \"poses\" in temp[0] else None\n",
    "        except Exception as e:\n",
    "            print(f\"Pred sim failed (temp={temp_val}): {e}\")\n",
    "            continue\n",
    "        print(Pp)\n",
    "        \n",
    "        if Pp is None:\n",
    "            continue\n",
    "\n",
    "        if P.shape[0] < minsteps:\n",
    "            continue\n",
    "\n",
    "        coup_idx_pred = coupler_index_for(mech_name)\n",
    "        if coup_idx_pred < 0:\n",
    "            continue\n",
    "        generated_x, generated_y = Pp[:, coup_idx_pred, 0], Pp[:, coup_idx_pred, 1]\n",
    "        if np.isnan(generated_x).any() or np.isinf(generated_x).any():\n",
    "            continue\n",
    "\n",
    "        # --- Align predicted to GT ---\n",
    "        gen_phi = -get_pca_inclination(generated_x, generated_y)\n",
    "        rotation = gen_phi - orig_phi\n",
    "        generated_x, generated_y = rotate_curve(generated_x, generated_y, rotation)\n",
    "        gen_denom = np.sqrt(np.var(generated_x) + np.var(generated_y)) + 1e-8\n",
    "        scale = orig_denom / gen_denom\n",
    "        generated_x *= scale\n",
    "        generated_y *= scale\n",
    "        gx_mean, gy_mean = np.mean(generated_x), np.mean(generated_y)\n",
    "        generated_x -= (gx_mean - ox_mean)\n",
    "        generated_y -= (gy_mean - oy_mean)\n",
    "\n",
    "        # --- Plot ---\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.plot(original_x, original_y, \"r-\", label=f\"GT Coupler ({gt_mech_name})\")\n",
    "        plt.plot(generated_x, generated_y, \"g--\", label=f\"Pred Coupler ({mech_name})\")\n",
    "\n",
    "        # Plot joint points\n",
    "        plt.scatter(gt_points[:, 0], gt_points[:, 1], color=\"red\", s=40, zorder=5)\n",
    "        for j, (x, y) in enumerate(gt_points):\n",
    "            plt.text(x, y, f\"J{j}\", color=\"red\", fontsize=9, weight=\"bold\")\n",
    "\n",
    "        plt.scatter(pred_points[:, 0], pred_points[:, 1], color=\"green\", s=40, zorder=5)\n",
    "        for j, (x, y) in enumerate(pred_points):\n",
    "            plt.text(x, y, f\"J{j}\", color=\"green\", fontsize=9, weight=\"bold\")\n",
    "\n",
    "        plt.axis(\"equal\")\n",
    "        plt.legend()\n",
    "        plt.title(f\"Sample {i} | GT={gt_mech_name} | Pred={mech_name} | Temp={temp_val}\")\n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(sample_dir, f\"temp_{temp_val:.1f}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "        print(f\"✅ Saved: {save_path}\")\n",
    "\n",
    "print(\"✅ Finished all temperature variations.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
