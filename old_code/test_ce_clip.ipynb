{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746bb70-eb1f-473e-bc2b-97abcf5067f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from model import SingleImageTransformerCLIP\n",
    "from dataset import BarLinkageDataset \n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "from curve_plot import get_pca_inclination, rotate_curve\n",
    "import scipy.spatial.distance as sciDist\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354fc90-9448-4531-ad0b-f95058e8fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headless simulator version\n",
    "index = 0 # local server index \n",
    "API_ENDPOINT = f\"http://localhost:4000/simulation\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "speedscale = 1\n",
    "steps = 360\n",
    "minsteps = int(steps*20/360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8ae72c-963c-458f-a536-c6737e88084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"weights/transformer_weights_17/d512_h8_n6_bs512_lr0.0001_best.pth\"\n",
    "data_dir = \"/home/anurizada/Documents/processed_dataset_17\"\n",
    "batch_size = 1\n",
    "\n",
    "dataset = BarLinkageDataset(data_dir=data_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4913484-58cd-4236-bc77-e3cf855f884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model_config = checkpoint['model_config']\n",
    "\n",
    "# Initialize model\n",
    "model = SingleImageTransformerCLIP(\n",
    "    tgt_seq_len=model_config['tgt_seq_len'],\n",
    "    d_model=model_config['d_model'],\n",
    "    h=model_config['h'],\n",
    "    N=model_config['N'],\n",
    "    num_labels=model_config['num_labels'],\n",
    "    vocab_size=model_config['vocab_size'] + 1,\n",
    ").to(device)\n",
    "\n",
    "# Load weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ad52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# If not already imported in your session:\n",
    "from curve_plot import get_pca_inclination, rotate_curve\n",
    "\n",
    "# ===================================\n",
    "# CONFIGURATION\n",
    "# ===================================\n",
    "label_mapping_path = \"/home/anurizada/Documents/processed_dataset_17/label_mapping.json\"\n",
    "coupler_mapping_path = \"/home/anurizada/Documents/transformer/BSIdict.json\"  # coupler info\n",
    "\n",
    "# --- load mappings ---\n",
    "with open(label_mapping_path, \"r\") as f:\n",
    "    label_mapping = json.load(f)\n",
    "index_to_label = label_mapping[\"index_to_label\"]              # {\"0\": \"RRRR\", ...}\n",
    "label_to_index = {v: int(k) for k, v in index_to_label.items()}  # {\"RRRR\": 0, ...}\n",
    "\n",
    "with open(coupler_mapping_path, \"r\") as f:\n",
    "    coupler_mapping = json.load(f)  # {\"RRRR\": {\"c\": [0,0,0,1,...]}, ...}\n",
    "\n",
    "# Limit to mech types 0..16, as requested\n",
    "MECH_MIN, MECH_MAX = 0, 16\n",
    "mechanism_types = [index_to_label[str(i)] for i in range(MECH_MIN, MECH_MAX + 1)]\n",
    "\n",
    "# --- coordinate binning setup ---\n",
    "class CoordinateBinner:\n",
    "    def __init__(self, kappa=1.0, num_bins=200):\n",
    "        self.kappa = kappa\n",
    "        self.num_bins = num_bins\n",
    "        self.bin_edges = np.linspace(-kappa, kappa, num_bins + 1)\n",
    "        self.bin_centers = (self.bin_edges[:-1] + self.bin_edges[1:]) / 2\n",
    "\n",
    "    def bin_to_value_torch(self, bin_index_tensor):\n",
    "        bin_index_tensor = torch.clamp(bin_index_tensor, 0, self.num_bins - 1)\n",
    "        device = bin_index_tensor.device\n",
    "        bin_centers_tensor = torch.tensor(self.bin_centers, device=device, dtype=torch.float32)\n",
    "        return bin_centers_tensor[bin_index_tensor]\n",
    "\n",
    "NUM_BINS = label_mapping[\"num_bins\"]\n",
    "BIN_OFFSET = 3  # (SOS, EOS, PAD) offset\n",
    "binner = CoordinateBinner(kappa=1.0, num_bins=NUM_BINS)\n",
    "\n",
    "print(f\"Loaded {len(index_to_label)} mechanism types (using 0..16).\")\n",
    "print(f\"Loaded coupler mapping with {len(coupler_mapping)} entries.\")\n",
    "print(\"Started\")\n",
    "\n",
    "start_time = time.time()\n",
    "sos_token, eos_token, pad_token = 0, 1, 2\n",
    "\n",
    "# You must define these elsewhere (you already had them):\n",
    "# API_ENDPOINT, HEADERS, speedscale, steps, minsteps\n",
    "\n",
    "# ===================================\n",
    "# HELPERS\n",
    "# ===================================\n",
    "def coupler_index_for(mech_type: str) -> int:\n",
    "    \"\"\"Return coupler curve index from BSIdict.json; -1 if unavailable.\"\"\"\n",
    "    if mech_type in coupler_mapping and \"c\" in coupler_mapping[mech_type]:\n",
    "        cvec = coupler_mapping[mech_type][\"c\"]\n",
    "        if isinstance(cvec, list) and 1 in cvec:\n",
    "            return cvec.index(1)\n",
    "    return -1\n",
    "\n",
    "def bins_to_continuous(seq, binner, bin_offset):\n",
    "    \"\"\"Convert a 1D array of vocab indices into continuous coords via binner.\"\"\"\n",
    "    seq = np.array(seq, dtype=np.int64)\n",
    "    numeric_mask = seq >= bin_offset\n",
    "    seq_numeric = seq[numeric_mask] - bin_offset\n",
    "    if seq_numeric.size == 0:\n",
    "        return np.array([], dtype=np.float32)\n",
    "    seq_tensor = torch.tensor(seq_numeric, dtype=torch.long)\n",
    "    seq_cont = binner.bin_to_value_torch(seq_tensor).cpu().numpy()\n",
    "    return seq_cont\n",
    "\n",
    "def predict_single_autoreg(model, image_tensor, mech_label_idx, max_seq_len, device,\n",
    "                           top_k=None, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Autoregressive decoding for a single image & single mech label (integer ID).\n",
    "    Greedy if top_k is None; else top-k sampling with the provided k.\n",
    "    Returns np.array of predicted token ids.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Ensure inputs on correct device; keep original tensors unmodified\n",
    "        image_1 = image_tensor.unsqueeze(0).to(device, non_blocking=True)\n",
    "        label_1 = torch.tensor([int(mech_label_idx)], device=device, dtype=torch.long)\n",
    "\n",
    "        # Start with SOS\n",
    "        decoder_input = torch.full((1, 1), sos_token, device=device, dtype=torch.long)\n",
    "        pred = []\n",
    "\n",
    "        for _ in range(max_seq_len):\n",
    "            T = decoder_input.size(1)\n",
    "            causal_mask = (torch.triu(torch.ones(T, T, device=device)) == 1).T  # [T,T]\n",
    "\n",
    "            logits, _, _ = model(decoder_input, causal_mask, image_1, label_1)\n",
    "            next_logits = logits[:, -1, :] / float(temperature)\n",
    "            probs = F.softmax(next_logits, dim=-1)\n",
    "\n",
    "            if top_k is None:\n",
    "                next_token = torch.argmax(probs, dim=-1)          # greedy\n",
    "            else:\n",
    "                k = min(int(top_k), probs.size(-1))\n",
    "                topk_probs, topk_idx = torch.topk(probs, k=k, dim=-1)\n",
    "                sampled = torch.multinomial(topk_probs, num_samples=1)  # [1,1]\n",
    "                next_token = topk_idx.gather(-1, sampled).squeeze(1)    # [1]\n",
    "\n",
    "            token = int(next_token.item())\n",
    "            pred.append(token)\n",
    "            decoder_input = torch.cat([decoder_input, next_token.unsqueeze(1)], dim=1)\n",
    "\n",
    "            if token == eos_token:\n",
    "                break\n",
    "\n",
    "    return np.array(pred, dtype=np.int64)\n",
    "\n",
    "# ===================================\n",
    "# ONE-BY-ONE INFERENCE OVER DATALOADER\n",
    "# ===================================\n",
    "device = next(model.parameters()).device  # use model's device (avoids cuda:0/cuda:1 mismatches)\n",
    "max_samples = 10\n",
    "# take model-configured length if present; otherwise derive from dataset targets\n",
    "model_tgt_len = getattr(model, \"model_config\", {}).get(\"tgt_seq_len\", None)\n",
    "\n",
    "samples_processed = 0\n",
    "\n",
    "for batch in tqdm(dataloader, desc=\"One-by-one inference\"):\n",
    "    if samples_processed >= max_samples:\n",
    "        break\n",
    "\n",
    "    # We process one sample at a time explicitly:\n",
    "    images = batch[\"images\"]              # (B, C, H, W)\n",
    "    labels_enc = batch[\"encoded_labels\"]  # (B,) int label IDs (as you stated)\n",
    "    targets_discrete = batch[\"labels_discrete\"]  # (B, T)\n",
    "\n",
    "    B = images.size(0)\n",
    "    for bi in range(B):\n",
    "        if samples_processed >= max_samples:\n",
    "            break\n",
    "\n",
    "        # ----- Prepare this single example -----\n",
    "        image = images[bi].cpu()  # keep on CPU; predict function will move to device\n",
    "        gt_label_idx = int(labels_enc[bi].item())  # you said it's integer-coded, not one-hot\n",
    "        gt_mech_type = index_to_label[str(gt_label_idx)]\n",
    "        out_dir = f\"results/sample_{samples_processed:03d}\"\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        # Prepare GT joints (for simulation of the reference/original curve)\n",
    "        tgt_seq = targets_discrete[bi].cpu().numpy()\n",
    "        tgt_seq = tgt_seq[tgt_seq != pad_token]  # strip PAD\n",
    "        # If EOS appears in target, you can truncate here (optional)\n",
    "        # eos_pos = np.where(tgt_seq == eos_token)[0]\n",
    "        # if eos_pos.size > 0: tgt_seq = tgt_seq[:eos_pos[0]]\n",
    "\n",
    "        tgt_cont = bins_to_continuous(tgt_seq, binner, BIN_OFFSET)\n",
    "        if tgt_cont.size % 2 == 1:\n",
    "            tgt_cont = tgt_cont[:-1]\n",
    "        if tgt_cont.size == 0:\n",
    "            samples_processed += 1\n",
    "            continue\n",
    "\n",
    "        gt_joints = tgt_cont.reshape(-1, 2)\n",
    "        gt_points = [gt_joints[j].tolist() for j in range(gt_joints.shape[0])]\n",
    "\n",
    "        # ----- Simulate the GT curve (red) -----\n",
    "        ex_gt = {\n",
    "            \"params\": gt_points,\n",
    "            \"type\": gt_mech_type,\n",
    "            \"speedScale\": speedscale,\n",
    "            \"steps\": steps,\n",
    "            \"relativeTolerance\": 0.1,\n",
    "        }\n",
    "        try:\n",
    "            temp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps([ex_gt])).json()\n",
    "            P = np.array(temp[0][\"poses\"]) if isinstance(temp, list) and temp and \"poses\" in temp[0] else None\n",
    "        except Exception:\n",
    "            samples_processed += 1\n",
    "            continue\n",
    "        if P is None or P.shape[0] < minsteps:\n",
    "            samples_processed += 1\n",
    "            continue\n",
    "\n",
    "        coup_idx_gt = coupler_index_for(gt_mech_type)\n",
    "        original_x, original_y = P[:, coup_idx_gt, 0], P[:, coup_idx_gt, 1]\n",
    "        orig_phi = -get_pca_inclination(original_x, original_y)\n",
    "        orig_denom = np.sqrt(np.var(original_x) + np.var(original_y)) + 1e-8\n",
    "        ox_mean, oy_mean = np.mean(original_x), np.mean(original_y)\n",
    "\n",
    "        # ----- Decode length: prefer model-configured length; fall back to target length -----\n",
    "        max_seq_len = int(model_tgt_len) if model_tgt_len is not None else int(targets_discrete.size(1))\n",
    "\n",
    "        # ----- Try mech types 0..16 one by one -----\n",
    "        for mech_idx in range(MECH_MIN, MECH_MAX + 1):\n",
    "            mech_type = index_to_label[str(mech_idx)]\n",
    "\n",
    "            # Predict sequence for this mech label\n",
    "            pred_seq = predict_single_autoreg(\n",
    "                model=model,\n",
    "                image_tensor=image,                    # moved to device inside\n",
    "                mech_label_idx=mech_idx,               # integer label id\n",
    "                max_seq_len=max_seq_len,\n",
    "                device=device,\n",
    "                top_k=True,                            # greedy by default; set an int for sampling\n",
    "                temperature=1.0\n",
    "            )\n",
    "            \n",
    "            print(pred_seq)\n",
    "            \n",
    "            # Convert to continuous coords\n",
    "            pred_cont = bins_to_continuous(pred_seq, binner, BIN_OFFSET)\n",
    "            if pred_cont.size % 2 == 1:\n",
    "                pred_cont = pred_cont[:-1]\n",
    "            if pred_cont.size == 0:\n",
    "                continue\n",
    "\n",
    "            pred_joints = pred_cont.reshape(-1, 2)\n",
    "            pred_points = [pred_joints[j].tolist() for j in range(pred_joints.shape[0])]\n",
    "\n",
    "            # Coupler index for predicted mech\n",
    "            coup_idx_pred = coupler_index_for(mech_type)\n",
    "\n",
    "            # Simulate predicted curve (green)\n",
    "            ex_pred = {\n",
    "                \"params\": pred_points,\n",
    "                \"type\": mech_type,\n",
    "                \"speedScale\": speedscale,\n",
    "                \"steps\": steps,\n",
    "                \"relativeTolerance\": 0.1,\n",
    "            }\n",
    "            try:\n",
    "                temp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps([ex_pred])).json()\n",
    "                Pp = np.array(temp[0][\"poses\"]) if isinstance(temp, list) and temp and \"poses\" in temp[0] else None\n",
    "            except Exception:\n",
    "                continue\n",
    "            if Pp is None or Pp.shape[0] < minsteps:\n",
    "                continue\n",
    "\n",
    "            generated_x, generated_y = Pp[:, coup_idx_pred, 0], Pp[:, coup_idx_pred, 1]\n",
    "            if np.isnan(generated_x).any() or np.isinf(generated_x).any() or len(generated_x) < 30:\n",
    "                continue\n",
    "\n",
    "            # Align predicted curve to GT\n",
    "            gen_phi = -get_pca_inclination(generated_x, generated_y)\n",
    "            rotation = gen_phi - orig_phi\n",
    "            generated_x, generated_y = rotate_curve(generated_x, generated_y, rotation)\n",
    "\n",
    "            gen_denom = np.sqrt(np.var(generated_x) + np.var(generated_y)) + 1e-8\n",
    "            scale = orig_denom / gen_denom\n",
    "            generated_x *= scale\n",
    "            generated_y *= scale\n",
    "\n",
    "            gx_mean, gy_mean = np.mean(generated_x), np.mean(generated_y)\n",
    "            generated_x -= (gx_mean - ox_mean)\n",
    "            generated_y -= (gy_mean - oy_mean)\n",
    "\n",
    "            # Plot both curves\n",
    "            plt.plot(original_x, original_y, \"r\", label=f\"GT ({gt_mech_type})\")\n",
    "            plt.plot(generated_x, generated_y, \"g\", label=f\"Pred: {mech_type}\")\n",
    "            plt.axis(\"equal\")\n",
    "            plt.legend()\n",
    "            plt.title(f\"Sample {samples_processed} | GT={gt_mech_type} | Pred={mech_type}\")\n",
    "            plt.savefig(os.path.join(out_dir, f\"{mech_type}.jpg\"))\n",
    "            plt.clf()\n",
    "\n",
    "        samples_processed += 1\n",
    "\n",
    "print(f\"✅ Finished all samples in {time.time() - start_time:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f15e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import time\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import requests\n",
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # ===================================\n",
    "# # CONFIGURATION\n",
    "# # ===================================\n",
    "# label_mapping_path = \"/home/anurizada/Documents/processed_dataset_17/label_mapping.json\"\n",
    "# coupler_mapping_path = \"/home/anurizada/Documents/transformer/BSIdict.json\"\n",
    "\n",
    "# with open(label_mapping_path, \"r\") as f:\n",
    "#     label_mapping = json.load(f)\n",
    "# index_to_label = label_mapping[\"index_to_label\"]\n",
    "\n",
    "# with open(coupler_mapping_path, \"r\") as f:\n",
    "#     coupler_mapping = json.load(f)\n",
    "\n",
    "# # --- coordinate binning setup ---\n",
    "# class CoordinateBinner:\n",
    "#     def __init__(self, kappa=1.0, num_bins=200):\n",
    "#         self.kappa = kappa\n",
    "#         self.num_bins = num_bins\n",
    "#         self.bin_edges = np.linspace(-kappa, kappa, num_bins + 1)\n",
    "#         self.bin_centers = (self.bin_edges[:-1] + self.bin_edges[1:]) / 2\n",
    "\n",
    "#     def bin_to_value_torch(self, bin_index_tensor):\n",
    "#         bin_index_tensor = torch.clamp(bin_index_tensor, 0, self.num_bins - 1)\n",
    "#         bin_centers_tensor = torch.tensor(self.bin_centers, device=bin_index_tensor.device, dtype=torch.float32)\n",
    "#         return bin_centers_tensor[bin_index_tensor]\n",
    "\n",
    "\n",
    "# # --- setup ---\n",
    "# NUM_BINS = label_mapping[\"num_bins\"]\n",
    "# BIN_OFFSET = 3\n",
    "# binner = CoordinateBinner(kappa=1.0, num_bins=NUM_BINS)\n",
    "\n",
    "# print(f\"Loaded label mapping with {len(index_to_label)} mechanism types.\")\n",
    "# print(f\"Loaded coupler mapping with {len(coupler_mapping)} entries.\")\n",
    "# print(f\"Coordinate binning: {NUM_BINS} bins, BIN_OFFSET={BIN_OFFSET}\")\n",
    "# print(\"Started\")\n",
    "# start_time = time.time()\n",
    "\n",
    "# # --- Tokens ---\n",
    "# sos_token = 0\n",
    "# eos_token = 1\n",
    "# pad_token = 2\n",
    "\n",
    "\n",
    "# # ===================================\n",
    "# # SINGLE-SAMPLE INFERENCE\n",
    "# # ===================================\n",
    "# def predict_single(model, image, label, max_seq_len, device, top_k=10, temperature=1.0, use_top_k=False):\n",
    "#     \"\"\"\n",
    "#     Autoregressive decoding for a single image and label (one at a time).\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         image = image.unsqueeze(0).to(device)\n",
    "#         label = label.unsqueeze(0).to(device)\n",
    "#         decoder_input = torch.full((1, 1), sos_token, device=device, dtype=torch.long)\n",
    "#         pred_seq = []\n",
    "\n",
    "#         for _ in range(max_seq_len):\n",
    "#             seq_len = decoder_input.shape[1]\n",
    "#             causal_mask = (torch.triu(torch.ones(seq_len, seq_len, device=device)) == 1).transpose(0, 1)\n",
    "#             preds, _, _ = model(decoder_input, causal_mask, image, label)\n",
    "#             next_logits = preds[:, -1, :] / temperature\n",
    "#             probs = F.softmax(next_logits, dim=-1)\n",
    "\n",
    "#             if use_top_k:\n",
    "#                 topk_probs, topk_indices = torch.topk(probs, k=min(top_k, probs.shape[-1]), dim=-1)\n",
    "#                 next_token_rel = torch.multinomial(topk_probs, num_samples=1)\n",
    "#                 next_token = topk_indices.gather(-1, next_token_rel).squeeze(1)\n",
    "#             else:\n",
    "#                 next_token = torch.argmax(probs, dim=-1)\n",
    "\n",
    "#             token_id = int(next_token.item())\n",
    "#             pred_seq.append(token_id)\n",
    "#             decoder_input = torch.cat([decoder_input, next_token.unsqueeze(1)], dim=1)\n",
    "#             if token_id == eos_token:\n",
    "#                 break\n",
    "\n",
    "#     return np.array(pred_seq)\n",
    "\n",
    "\n",
    "# # ===================================\n",
    "# # RUN INFERENCE ONE-BY-ONE\n",
    "# # ===================================\n",
    "# device = next(model.parameters()).device\n",
    "# max_samples = 100\n",
    "# predictions, targets, label_indices = [], [], []\n",
    "# samples_processed = 0\n",
    "\n",
    "# for batch in tqdm(dataloader, desc=\"Running one-by-one inference\"):\n",
    "#     if samples_processed >= max_samples:\n",
    "#         break\n",
    "\n",
    "#     images = batch[\"images\"]\n",
    "#     labels = batch[\"encoded_labels\"]\n",
    "#     targets_discrete = batch[\"labels_discrete\"]\n",
    "\n",
    "#     for i in range(images.shape[0]):\n",
    "#         if samples_processed >= max_samples:\n",
    "#             break\n",
    "\n",
    "#         image = images[i]\n",
    "#         label = labels[i]\n",
    "#         target_seq = targets_discrete[i].cpu().numpy()\n",
    "#         target_seq = target_seq[target_seq != pad_token]\n",
    "\n",
    "#         label_idx = int(label.item()) if label.numel() == 1 else int(torch.argmax(label).item())\n",
    "#         mech_type = index_to_label[str(label_idx)]\n",
    "\n",
    "#         max_seq_len = model.model_config[\"tgt_seq_len\"] if hasattr(model, \"model_config\") else len(target_seq)\n",
    "\n",
    "#         pred_seq = predict_single(model, image, label, max_seq_len, device, top_k=10, temperature=1.0, use_top_k=False)\n",
    "\n",
    "#         predictions.append(pred_seq)\n",
    "#         targets.append(target_seq)\n",
    "#         label_indices.append(label_idx)\n",
    "#         samples_processed += 1\n",
    "\n",
    "# print(f\"✅ Processed {samples_processed} samples individually.\")\n",
    "\n",
    "\n",
    "# # ===================================\n",
    "# # CONVERT BINS → CONTINUOUS COORDINATES\n",
    "# # ===================================\n",
    "# def bins_to_continuous(seq, binner, bin_offset):\n",
    "#     seq = np.array(seq)\n",
    "#     numeric_mask = seq >= bin_offset\n",
    "#     seq_numeric = seq[numeric_mask] - bin_offset\n",
    "#     if len(seq_numeric) == 0:\n",
    "#         return np.array([])\n",
    "#     seq_tensor = torch.tensor(seq_numeric, dtype=torch.long)\n",
    "#     seq_cont = binner.bin_to_value_torch(seq_tensor).cpu().numpy()\n",
    "#     return seq_cont\n",
    "\n",
    "\n",
    "# # ===================================\n",
    "# # SIMULATION LOOP\n",
    "# # ===================================\n",
    "# for idx, (pred_seq, target_seq, label_idx) in enumerate(zip(predictions, targets, label_indices)):\n",
    "#     mech_type = index_to_label[str(label_idx)]\n",
    "\n",
    "#     if mech_type in coupler_mapping and \"c\" in coupler_mapping[mech_type]:\n",
    "#         cvec = coupler_mapping[mech_type][\"c\"]\n",
    "#         couplerCurveIndex = cvec.index(1) if 1 in cvec else -1\n",
    "#     else:\n",
    "#         couplerCurveIndex = -1\n",
    "\n",
    "#     pred_cont = bins_to_continuous(pred_seq, binner, BIN_OFFSET)\n",
    "#     target_cont = bins_to_continuous(target_seq, binner, BIN_OFFSET)\n",
    "\n",
    "#     if len(pred_cont) % 2 == 1:\n",
    "#         pred_cont = pred_cont[:-1]\n",
    "#     if len(target_cont) % 2 == 1:\n",
    "#         target_cont = target_cont[:-1]\n",
    "\n",
    "#     if len(pred_cont) == 0 or len(target_cont) == 0:\n",
    "#         continue\n",
    "\n",
    "#     pred_joints = pred_cont.reshape(-1, 2)\n",
    "#     gt_joints = target_cont.reshape(-1, 2)\n",
    "#     num_joints = gt_joints.shape[0]\n",
    "\n",
    "#     j_points_gt = [gt_joints[i].tolist() for i in range(num_joints)]\n",
    "#     j_points_pred = [pred_joints[i].tolist() for i in range(min(num_joints, pred_joints.shape[0]))]\n",
    "\n",
    "#     # --- ORIGINAL MECHANISM SIMULATION ---\n",
    "#     exampleData = {\n",
    "#         \"params\": j_points_gt,\n",
    "#         \"type\": mech_type,\n",
    "#         \"speedScale\": speedscale,\n",
    "#         \"steps\": steps,\n",
    "#         \"relativeTolerance\": 0.1,\n",
    "#     }\n",
    "\n",
    "#     try:\n",
    "#         temp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps([exampleData])).json()\n",
    "#         time.sleep(0.05)\n",
    "#     except ValueError:\n",
    "#         continue\n",
    "\n",
    "#     if temp[0][\"poses\"] is None:\n",
    "#         continue\n",
    "\n",
    "#     P = np.array(temp[0][\"poses\"])\n",
    "#     if P.shape[0] < minsteps:\n",
    "#         continue\n",
    "\n",
    "#     original_x, original_y = P[:, couplerCurveIndex, 0], P[:, couplerCurveIndex, 1]\n",
    "#     original_phi = -get_pca_inclination(original_x, original_y)\n",
    "#     original_denom = np.sqrt(np.var(original_x) + np.var(original_y))\n",
    "#     original_mean_x, original_mean_y = np.mean(original_x), np.mean(original_y)\n",
    "\n",
    "#     # --- PREDICTED MECHANISM SIMULATION ---\n",
    "#     exampleData[\"params\"] = j_points_pred\n",
    "#     try:\n",
    "#         temp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps([exampleData])).json()\n",
    "#         time.sleep(0.05)\n",
    "#     except ValueError:\n",
    "#         continue\n",
    "#     if temp[0][\"poses\"] is None:\n",
    "#         continue\n",
    "#     P = np.array(temp[0][\"poses\"])\n",
    "#     if P.shape[0] < minsteps:\n",
    "#         continue\n",
    "\n",
    "#     generated_x, generated_y = P[:, couplerCurveIndex, 0], P[:, couplerCurveIndex, 1]\n",
    "#     if np.isnan(generated_x).any() or np.isinf(generated_x).any() or len(generated_x) < 30:\n",
    "#         continue\n",
    "\n",
    "#     generated_phi = -get_pca_inclination(generated_x, generated_y)\n",
    "#     rotation = generated_phi - original_phi\n",
    "#     generated_x, generated_y = rotate_curve(generated_x, generated_y, rotation)\n",
    "\n",
    "#     generated_denom = np.sqrt(np.var(generated_x) + np.var(generated_y))\n",
    "#     scale_factor = original_denom / (generated_denom + 1e-8)\n",
    "#     generated_x *= scale_factor\n",
    "#     generated_y *= scale_factor\n",
    "\n",
    "#     generated_mean_x, generated_mean_y = np.mean(generated_x), np.mean(generated_y)\n",
    "#     translation_x, translation_y = generated_mean_x - original_mean_x, generated_mean_y - original_mean_y\n",
    "#     generated_x -= translation_x\n",
    "#     generated_y -= translation_y\n",
    "\n",
    "#     # --- PLOT BOTH CURVES ---\n",
    "#     plt.plot(original_x, original_y, \"r\", label=\"original\")\n",
    "#     plt.plot(generated_x, generated_y, \"g\", label=\"predicted\")\n",
    "#     plt.title(f\"Mechanism: {mech_type} | Coupler index: {couplerCurveIndex}\")\n",
    "#     plt.axis(\"equal\")\n",
    "#     plt.legend()\n",
    "\n",
    "#     out_dir = f\"results/{idx}\"\n",
    "#     os.makedirs(out_dir, exist_ok=True)\n",
    "#     plt.savefig(f\"{out_dir}/{idx}_{mech_type}_iter_pred.jpg\")\n",
    "#     plt.clf()\n",
    "\n",
    "# print(f\"✅ Finished all samples in {time.time() - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1fecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# import requests\n",
    "# import time\n",
    "# import os\n",
    "# from curve_plot import get_pca_inclination, rotate_curve\n",
    "\n",
    "# # ===================================\n",
    "# # CONFIGURATION\n",
    "# # ===================================\n",
    "# label_mapping_path = \"/home/anurizada/Documents/processed_dataset_17/label_mapping.json\"\n",
    "# with open(label_mapping_path, \"r\") as f:\n",
    "#     label_mapping = json.load(f)\n",
    "# index_to_label = label_mapping[\"index_to_label\"]\n",
    "\n",
    "# # --- coordinate binning setup ---\n",
    "# class CoordinateBinner:\n",
    "#     def __init__(self, kappa=1.0, num_bins=200):\n",
    "#         self.kappa = kappa\n",
    "#         self.num_bins = num_bins\n",
    "#         self.bin_edges = np.linspace(-kappa, kappa, num_bins + 1)\n",
    "#         self.bin_centers = (self.bin_edges[:-1] + self.bin_edges[1:]) / 2\n",
    "\n",
    "#     def bin_to_value_torch(self, bin_index_tensor):\n",
    "#         bin_index_tensor = torch.clamp(bin_index_tensor, 0, self.num_bins - 1)\n",
    "#         bin_centers_tensor = torch.tensor(self.bin_centers, device=bin_index_tensor.device, dtype=torch.float32)\n",
    "#         return bin_centers_tensor[bin_index_tensor]\n",
    "\n",
    "# # from your label_mapping.json\n",
    "# NUM_BINS = label_mapping[\"num_bins\"]\n",
    "# BIN_OFFSET = 3  # usually 3\n",
    "# binner = CoordinateBinner(kappa=1.0, num_bins=NUM_BINS)\n",
    "\n",
    "# print(f\"Loaded label mapping with {len(index_to_label)} mechanism types.\")\n",
    "# print(f\"Coordinate binning: {NUM_BINS} bins, BIN_OFFSET={BIN_OFFSET}\")\n",
    "\n",
    "# print('Started')\n",
    "# start_time = time.time()\n",
    "\n",
    "# eos_token = 1\n",
    "# pad_token = 2\n",
    "\n",
    "# # ===================================\n",
    "# # BATCH INFERENCE\n",
    "# # ===================================\n",
    "# def predict_batch(model, dataloader, max_samples=100, device=\"cuda\"):\n",
    "#     all_predictions, all_targets, all_labels = [], [], []\n",
    "#     samples_processed = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(dataloader, desc=\"Running batch inference\"):\n",
    "#             if samples_processed >= max_samples:\n",
    "#                 break\n",
    "\n",
    "#             decoder_input = batch[\"decoder_input_discrete\"].to(device)\n",
    "#             decoder_mask = batch[\"causal_mask\"].to(device)\n",
    "#             images = batch[\"images\"].to(device)\n",
    "#             encoded_labels = batch[\"encoded_labels\"].to(device)\n",
    "#             target_tokens = batch[\"labels_discrete\"].to(device)\n",
    "\n",
    "#             predictions, _, _ = model(decoder_input, decoder_mask, images, encoded_labels)\n",
    "#             pred_tokens = predictions.argmax(dim=-1)\n",
    "\n",
    "#             for i in range(pred_tokens.shape[0]):\n",
    "#                 if samples_processed >= max_samples:\n",
    "#                     break\n",
    "\n",
    "#                 pred_seq = pred_tokens[i].cpu().numpy()\n",
    "#                 target_seq = target_tokens[i].cpu().numpy()\n",
    "\n",
    "#                 valid_mask = target_seq != pad_token\n",
    "#                 pred_seq = pred_seq[valid_mask]\n",
    "#                 target_seq = target_seq[valid_mask]\n",
    "\n",
    "#                 if eos_token in pred_seq:\n",
    "#                     pred_seq = pred_seq[: np.where(pred_seq == eos_token)[0][0]]\n",
    "#                 if eos_token in target_seq:\n",
    "#                     target_seq = target_seq[: np.where(target_seq == eos_token)[0][0]]\n",
    "\n",
    "#                 # get label index from one-hot or already-int encoded tensor\n",
    "#                 label_idx = encoded_labels[i].item()\n",
    "\n",
    "#                 all_predictions.append(pred_seq)\n",
    "#                 all_targets.append(target_seq)\n",
    "#                 all_labels.append(label_idx)\n",
    "#                 samples_processed += 1\n",
    "\n",
    "#     print(f\"\\nProcessed {samples_processed} samples total\")\n",
    "#     return all_predictions, all_targets, all_labels\n",
    "\n",
    "\n",
    "# # ===================================\n",
    "# # RUN INFERENCE\n",
    "# # ===================================\n",
    "# max_samples = 20\n",
    "# predictions, targets, label_indices = predict_batch(model, dataloader, max_samples=max_samples, device=device)\n",
    "# print(label_indices)\n",
    "\n",
    "# # ===================================\n",
    "# # CONVERT BINS → CONTINUOUS COORDINATES\n",
    "# # ===================================\n",
    "# def bins_to_continuous(seq, binner, bin_offset):\n",
    "#     seq = np.array(seq)\n",
    "#     # remove special tokens (anything below BIN_OFFSET)\n",
    "#     numeric_mask = seq >= bin_offset\n",
    "#     seq_numeric = seq[numeric_mask] - bin_offset\n",
    "#     seq_tensor = torch.tensor(seq_numeric, dtype=torch.long)\n",
    "#     seq_cont = binner.bin_to_value_torch(seq_tensor).cpu().numpy()\n",
    "#     return seq_cont\n",
    "\n",
    "\n",
    "# # ===================================\n",
    "# # SIMULATION LOOP\n",
    "# # ===================================\n",
    "# for idx, (pred_seq, target_seq, label_idx) in enumerate(zip(predictions, targets, label_indices)):\n",
    "#     mech_type = index_to_label[str(label_idx)]\n",
    "\n",
    "#     # Convert discrete bins → continuous coords\n",
    "#     pred_cont = bins_to_continuous(pred_seq, binner, BIN_OFFSET)\n",
    "#     target_cont = bins_to_continuous(target_seq, binner, BIN_OFFSET)\n",
    "\n",
    "#     # Drop odd lengths to form (N, 2)\n",
    "#     if len(pred_cont) % 2 == 1:\n",
    "#         pred_cont = pred_cont[:-1]\n",
    "#     if len(target_cont) % 2 == 1:\n",
    "#         target_cont = target_cont[:-1]\n",
    "\n",
    "#     pred_joints = pred_cont.reshape(-1, 2)\n",
    "#     gt_joints = target_cont.reshape(-1, 2)\n",
    "#     num_joints = gt_joints.shape[0]\n",
    "\n",
    "#     j_points_gt = [gt_joints[i].tolist() for i in range(num_joints)]\n",
    "#     j_points_pred = [pred_joints[i].tolist() for i in range(min(num_joints, pred_joints.shape[0]))]\n",
    "#     couplerCurveIndex = num_joints - 1  # last joint as coupler\n",
    "\n",
    "#     # --- ORIGINAL MECHANISM SIMULATION ---\n",
    "#     exampleData = {\n",
    "#         \"params\": j_points_gt,\n",
    "#         \"type\": mech_type,\n",
    "#         \"speedScale\": speedscale,\n",
    "#         \"steps\": steps,\n",
    "#         \"relativeTolerance\": 0.1,\n",
    "#     }\n",
    "\n",
    "#     try:\n",
    "#         temp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps([exampleData])).json()\n",
    "#         time.sleep(0.05)\n",
    "#     except ValueError:\n",
    "#         continue\n",
    "\n",
    "#     if temp[0][\"poses\"] is None:\n",
    "#         continue\n",
    "\n",
    "#     P = np.array(temp[0][\"poses\"])\n",
    "#     if P.shape[0] < minsteps:\n",
    "#         continue\n",
    "\n",
    "#     original_x, original_y = P[:, couplerCurveIndex, 0], P[:, couplerCurveIndex, 1]\n",
    "#     original_mean_x, original_mean_y = np.mean(original_x), np.mean(original_y)\n",
    "#     original_denom = np.sqrt(np.var(original_x) + np.var(original_y))\n",
    "#     original_phi = -get_pca_inclination(original_x, original_y)\n",
    "\n",
    "#     # --- PREDICTED MECHANISM SIMULATION ---\n",
    "    \n",
    "#     exampleData[\"params\"] = j_points_pred\n",
    "#     try:\n",
    "#         temp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps([exampleData])).json()\n",
    "#         time.sleep(0.05)\n",
    "#     except ValueError:\n",
    "#         continue\n",
    "\n",
    "#     if temp[0][\"poses\"] is None:\n",
    "#         continue\n",
    "\n",
    "#     P = np.array(temp[0][\"poses\"])\n",
    "#     if P.shape[0] < minsteps:\n",
    "#         continue\n",
    "\n",
    "#     generated_x, generated_y = P[:, couplerCurveIndex, 0], P[:, couplerCurveIndex, 1]\n",
    "#     if np.isnan(generated_x).any() or np.isinf(generated_x).any() or len(generated_x) < 30:\n",
    "#         continue\n",
    "\n",
    "#     # --- ALIGN CURVES ---\n",
    "#     generated_phi = -get_pca_inclination(generated_x, generated_y)\n",
    "#     rotation = generated_phi - original_phi\n",
    "#     generated_x, generated_y = rotate_curve(generated_x, generated_y, rotation)\n",
    "\n",
    "#     generated_denom = np.sqrt(np.var(generated_x) + np.var(generated_y))\n",
    "#     scale_factor = original_denom / generated_denom\n",
    "#     generated_x, generated_y = np.multiply(generated_x, scale_factor), np.multiply(generated_y, scale_factor)\n",
    "\n",
    "#     generated_mean_x, generated_mean_y = np.mean(generated_x), np.mean(generated_y)\n",
    "#     translation_x, translation_y = generated_mean_x - original_mean_x, generated_mean_y - original_mean_y\n",
    "#     generated_x, generated_y = np.subtract(generated_x, translation_x), np.subtract(generated_y, translation_y)\n",
    "\n",
    "#     # --- PLOT BOTH CURVES ---\n",
    "#     plt.plot(original_x, original_y, \"r\", label=\"original\")\n",
    "#     plt.plot(generated_x, generated_y, \"g\", label=\"predicted\")\n",
    "#     plt.title(f\"Mechanism: {mech_type}\")\n",
    "#     plt.axis(\"equal\")\n",
    "#     plt.legend()\n",
    "\n",
    "#     out_dir = f\"results/{idx}\"\n",
    "#     os.makedirs(out_dir, exist_ok=True)\n",
    "#     plt.savefig(f\"{out_dir}/{idx}_{mech_type}_batch_pred.jpg\")\n",
    "#     plt.clf()\n",
    "\n",
    "# print(f\"Finished in {time.time() - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0227c5-47f5-4869-8a9c-9d3a5e358398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !rm results.zip\n",
    "# !zip -r results.zip results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
